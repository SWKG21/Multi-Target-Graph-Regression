{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 映射 合并 归零\n",
    "# import numpy as np\n",
    "# emb = np.load('embeddings_p2q_5_wl10.npy')\n",
    "# fea = np.load('node_features.npy')\n",
    "# emb[:,:13] = (emb[:,:13]+1)/2\n",
    "# embed = np.concatenate((emb, fea), axis=1)\n",
    "# embed[-1] = np.zeros(embed.shape[1])\n",
    "# np.save('data/embeddings_p2q_5_wl10.npy', embed, allow_pickle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 2219
    },
    "colab_type": "code",
    "id": "4H4EJY3OQNmB",
    "outputId": "11df12bd-34bf-43a8-bc5e-7003a5affa2f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "model compiled\n",
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/100\n",
      "59980/59980 [==============================] - 157s 3ms/step - loss: 0.6776 - mean_absolute_error: 0.6060 - val_loss: 0.5582 - val_mean_absolute_error: 0.5157\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.55819, saving model to data/model_sc2\n",
      "Epoch 2/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.5288 - mean_absolute_error: 0.5225 - val_loss: 0.5099 - val_mean_absolute_error: 0.4917\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.55819 to 0.50988, saving model to data/model_sc2\n",
      "Epoch 3/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4948 - mean_absolute_error: 0.5049 - val_loss: 0.5003 - val_mean_absolute_error: 0.4917\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.50988 to 0.50027, saving model to data/model_sc2\n",
      "Epoch 4/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4781 - mean_absolute_error: 0.4962 - val_loss: 0.4813 - val_mean_absolute_error: 0.4790\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.50027 to 0.48132, saving model to data/model_sc2\n",
      "Epoch 5/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4691 - mean_absolute_error: 0.4925 - val_loss: 0.4797 - val_mean_absolute_error: 0.4686\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.48132 to 0.47970, saving model to data/model_sc2\n",
      "Epoch 6/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4605 - mean_absolute_error: 0.4864 - val_loss: 0.4633 - val_mean_absolute_error: 0.4683\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.47970 to 0.46334, saving model to data/model_sc2\n",
      "Epoch 7/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4458 - mean_absolute_error: 0.4779 - val_loss: 0.4528 - val_mean_absolute_error: 0.4627\n",
      "\n",
      "Epoch 00007: val_loss improved from 0.46334 to 0.45276, saving model to data/model_sc2\n",
      "Epoch 8/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4392 - mean_absolute_error: 0.4743 - val_loss: 0.4527 - val_mean_absolute_error: 0.4634\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.45276 to 0.45274, saving model to data/model_sc2\n",
      "Epoch 9/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4306 - mean_absolute_error: 0.4707 - val_loss: 0.4435 - val_mean_absolute_error: 0.4588\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.45274 to 0.44346, saving model to data/model_sc2\n",
      "Epoch 10/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.4253 - mean_absolute_error: 0.4682 - val_loss: 0.4396 - val_mean_absolute_error: 0.4582\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.44346 to 0.43958, saving model to data/model_sc2\n",
      "Epoch 11/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4219 - mean_absolute_error: 0.4663 - val_loss: 0.4315 - val_mean_absolute_error: 0.4480\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.43958 to 0.43151, saving model to data/model_sc2\n",
      "Epoch 12/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4162 - mean_absolute_error: 0.4623 - val_loss: 0.4307 - val_mean_absolute_error: 0.4524\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.43151 to 0.43068, saving model to data/model_sc2\n",
      "Epoch 13/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.4113 - mean_absolute_error: 0.4585 - val_loss: 0.4156 - val_mean_absolute_error: 0.4411\n",
      "\n",
      "Epoch 00013: val_loss improved from 0.43068 to 0.41557, saving model to data/model_sc2\n",
      "Epoch 14/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.4059 - mean_absolute_error: 0.4583 - val_loss: 0.4153 - val_mean_absolute_error: 0.4430\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.41557 to 0.41527, saving model to data/model_sc2\n",
      "Epoch 15/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.4012 - mean_absolute_error: 0.4542 - val_loss: 0.4211 - val_mean_absolute_error: 0.4495\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.41527\n",
      "Epoch 16/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3961 - mean_absolute_error: 0.4521 - val_loss: 0.4105 - val_mean_absolute_error: 0.4406\n",
      "\n",
      "Epoch 00016: val_loss improved from 0.41527 to 0.41046, saving model to data/model_sc2\n",
      "Epoch 17/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3941 - mean_absolute_error: 0.4503 - val_loss: 0.4127 - val_mean_absolute_error: 0.4450\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.41046\n",
      "Epoch 18/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3893 - mean_absolute_error: 0.4491 - val_loss: 0.4119 - val_mean_absolute_error: 0.4431\n",
      "\n",
      "Epoch 00018: val_loss did not improve from 0.41046\n",
      "Epoch 19/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3887 - mean_absolute_error: 0.4485 - val_loss: 0.3960 - val_mean_absolute_error: 0.4317\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.41046 to 0.39605, saving model to data/model_sc2\n",
      "Epoch 20/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3848 - mean_absolute_error: 0.4471 - val_loss: 0.3985 - val_mean_absolute_error: 0.4369\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.39605\n",
      "Epoch 21/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3779 - mean_absolute_error: 0.4442 - val_loss: 0.3904 - val_mean_absolute_error: 0.4313\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.39605 to 0.39039, saving model to data/model_sc2\n",
      "Epoch 22/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3727 - mean_absolute_error: 0.4403 - val_loss: 0.4007 - val_mean_absolute_error: 0.4372\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.39039\n",
      "Epoch 23/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.3702 - mean_absolute_error: 0.4401 - val_loss: 0.3931 - val_mean_absolute_error: 0.4327\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.39039\n",
      "Epoch 24/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3658 - mean_absolute_error: 0.4380 - val_loss: 0.3787 - val_mean_absolute_error: 0.4239\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.39039 to 0.37866, saving model to data/model_sc2\n",
      "Epoch 25/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3644 - mean_absolute_error: 0.4362 - val_loss: 0.3853 - val_mean_absolute_error: 0.4273\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.37866\n",
      "Epoch 26/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.3631 - mean_absolute_error: 0.4355 - val_loss: 0.4311 - val_mean_absolute_error: 0.4500\n",
      "\n",
      "Epoch 00026: val_loss did not improve from 0.37866\n",
      "Epoch 27/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3585 - mean_absolute_error: 0.4354 - val_loss: 0.3972 - val_mean_absolute_error: 0.4387\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.37866\n",
      "Epoch 28/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3586 - mean_absolute_error: 0.4337 - val_loss: 0.3951 - val_mean_absolute_error: 0.4309\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.37866\n",
      "Epoch 29/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.3569 - mean_absolute_error: 0.4325 - val_loss: 0.3946 - val_mean_absolute_error: 0.4325\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.37866\n",
      "* * * * * * * target 2 done * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import json\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, TimeDistributed, Dense, Add, add\n",
    "from keras.layers import LeakyReLU, BatchNormalization\n",
    "\n",
    "from utils import *\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "from StructuredSelfAttentive import StructuredSelfAttentive\n",
    "from AttentionWithMultiContext import AttentionWithMultiContext\n",
    "from SkipConnection import SkipConnection\n",
    "\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "is_GPU = True\n",
    "save_weights = True\n",
    "save_history = True\n",
    "\n",
    "path_root = ''\n",
    "path_to_code = path_root\n",
    "path_to_data = path_root + 'data/'\n",
    "\n",
    "sys.path.insert(0, path_to_code)\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "# = = = = = hyper-parameters = = = = =\n",
    "\n",
    "n_units = 60\n",
    "mc_n_units = 100\n",
    "da = 15\n",
    "r = 10\n",
    "drop_rate = 0.2\n",
    "batch_size = 200\n",
    "nb_epochs = 100\n",
    "my_optimizer = 'adam'\n",
    "my_patience = 5\n",
    "\n",
    "\n",
    "# = = = = = data loading = = = = =\n",
    "\n",
    "docs = np.load(path_to_data + 'documents_p2q_5_wl10.npy')\n",
    "embeddings = np.load(path_to_data + 'embeddings_p2q_5_wl10.npy')\n",
    "\n",
    "with open(path_to_data + 'train_idxs.txt', 'r') as file:\n",
    "    train_idxs = file.read().splitlines()\n",
    "    \n",
    "train_idxs = [int(elt) for elt in train_idxs]\n",
    "\n",
    "# create validation set\n",
    "np.random.seed(12219)\n",
    "# np.random.seed(1)\n",
    "idxs_select_train = np.random.choice(range(len(train_idxs)),size=int(len(train_idxs)*0.80),replace=False)\n",
    "idxs_select_val = np.setdiff1d(range(len(train_idxs)),idxs_select_train)\n",
    "\n",
    "train_idxs_new = [train_idxs[elt] for elt in idxs_select_train]\n",
    "val_idxs = [train_idxs[elt] for elt in idxs_select_val]\n",
    "\n",
    "docs_train = docs[train_idxs_new,:,:]\n",
    "docs_val = docs[val_idxs,:,:]\n",
    "\n",
    "tgt = 2\n",
    "\n",
    "with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:\n",
    "    target = file.read().splitlines()\n",
    "\n",
    "target_train = np.array([target[elt] for elt in idxs_select_train]).astype('float')\n",
    "target_val = np.array([target[elt] for elt in idxs_select_val]).astype('float')\n",
    "\n",
    "print('data loaded')\n",
    "\n",
    "# = = = = = defining architecture = = = = =\n",
    "\n",
    "sent_ints = Input(shape=(docs_train.shape[2],))\n",
    "\n",
    "sent_wv = Embedding(input_dim=embeddings.shape[0],\n",
    "                    output_dim=embeddings.shape[1],\n",
    "                    weights=[embeddings],\n",
    "                    input_length=docs_train.shape[2],\n",
    "                    trainable=False,\n",
    "                    )(sent_ints)\n",
    "\n",
    "## HAN sent encoder\n",
    "sent_wv_dr = Dropout(drop_rate)(sent_wv)\n",
    "# sent_wv_dr = BatchNormalization(sent_wv_dr) ######\n",
    "sent_wa = bidir_gru(sent_wv_dr, n_units, is_GPU)\n",
    "sent_wa = bidir_gru(sent_wa, n_units, is_GPU) #########\n",
    "sent_att_vec, word_att_coeffs = AttentionWithContext(return_coefficients=True)(sent_wa)\n",
    "sent_att_vec_dr = Dropout(drop_rate)(sent_att_vec)\n",
    "# sent_att_vec_dr = BatchNormalization(sent_att_vec_dr) ######\n",
    "# skip connection\n",
    "sent_added = SkipConnection()([sent_att_vec_dr, sent_wv_dr])\n",
    "sent_encoder = Model(sent_ints, sent_added)\n",
    "\n",
    "## structured self-attentive\n",
    "mc_sent_wv_dr = Dropout(drop_rate)(sent_wv)\n",
    "# mc_sent_wv_dr = BatchNormalization(mc_sent_wv_dr) ######\n",
    "mc_sent_wa = bidir_lstm(mc_sent_wv_dr, mc_n_units, is_GPU)\n",
    "mc_sent_wa = bidir_lstm(mc_sent_wa, mc_n_units, is_GPU) #######\n",
    "mc_sent_att_vec, mc_word_att_coeffs = StructuredSelfAttentive(da=da, r=r, return_coefficients=True)(mc_sent_wa)\n",
    "mc_sent_att_vec_dr = Dropout(drop_rate)(mc_sent_att_vec)\n",
    "# mc_sent_att_vec_dr = BatchNormalization(mc_sent_att_vec_dr) ######\n",
    "# skip connection\n",
    "mc_sent_added = SkipConnection()([mc_sent_att_vec_dr, mc_sent_wv_dr])\n",
    "mc_sent_encoder = Model(sent_ints, mc_sent_added)\n",
    "\n",
    "## combine context and target\n",
    "doc_ints = Input(shape=(docs_train.shape[1], docs_train.shape[2],))\n",
    "# sentence encoder\n",
    "sent_att_vecs_dr = TimeDistributed(sent_encoder)(doc_ints)\n",
    "doc_sa = bidir_gru(sent_att_vecs_dr, n_units, is_GPU)\n",
    "# context\n",
    "mc_sent_att_vecs_dr = TimeDistributed(mc_sent_encoder)(doc_ints)\n",
    "mc_doc_sa = bidir_gru(mc_sent_att_vecs_dr, n_units, is_GPU)\n",
    "\n",
    "doc_att_vec, sent_att_coeffs = AttentionWithMultiContext(return_coefficients=True)([doc_sa, mc_doc_sa])\n",
    "doc_att_vec_dr = Dropout(drop_rate)(doc_att_vec)\n",
    "# doc_att_vec_dr = BatchNormalization(doc_att_vec_dr) ######\n",
    "\n",
    "# new\n",
    "# hid = Dense(units=4, activation='tanh')(doc_att_vec_dr)\n",
    "# hid1 = Dense(units=16, activation='relu')(doc_att_vec_dr) ###\n",
    "# hid1r = Dropout(drop_rate)(hid1)\n",
    "# hid2 = Dense(units=16, activation='relu')(hid1r)\n",
    "# hid2r = Dropout(drop_rate)(hid2)\n",
    "# hid3 = Dense(units=16, activation='relu')(hid2r)\n",
    "# hid3r = Dropout(drop_rate)(hid3)\n",
    "# hid4 = Dense(units=16, activation='relu')(hid3r)\n",
    "# hid4r = Dropout(drop_rate)(hid4)\n",
    "#   hid1 = Dense(units=32, activation='sigmoid')(doc_att_vec_dr)\n",
    "#   hid2 = Dense(units=8, activation='sigmoid')(hid1)\n",
    "hid1 = LeakyReLU(alpha=0.01)(doc_att_vec_dr)\n",
    "hid2 = LeakyReLU(alpha=0.01)(hid1)\n",
    "preds = Dense(units=1)(hid2)\n",
    "\n",
    "model = Model(doc_ints, preds)\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer=my_optimizer, metrics=['mae'])\n",
    "\n",
    "print('model compiled')\n",
    "\n",
    "# = = = = = training = = = = =\n",
    "\n",
    "early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                patience=my_patience,\n",
    "                                mode='min')\n",
    "\n",
    "# save model corresponding to best epoch\n",
    "checkpointer = ModelCheckpoint(filepath=path_to_data + 'model_sc' + str(tgt), \n",
    "                                verbose=1, \n",
    "                                save_best_only=True,\n",
    "                                save_weights_only=True)\n",
    "\n",
    "if save_weights:\n",
    "    my_callbacks = [early_stopping, checkpointer]\n",
    "else:\n",
    "    my_callbacks = [early_stopping]\n",
    "\n",
    "model.fit(docs_train, \n",
    "            target_train,\n",
    "            batch_size = batch_size,\n",
    "            epochs = nb_epochs,\n",
    "            validation_data = (docs_val,target_val),\n",
    "            callbacks = my_callbacks)\n",
    "\n",
    "hist = model.history.history\n",
    "\n",
    "if save_history:\n",
    "    with open(path_to_data + 'model_history_sc' + str(tgt) + '_sc.json', 'w') as file:\n",
    "        json.dump(hist, file, sort_keys=False, indent=4)\n",
    "\n",
    "print('* * * * * * * target',tgt,'done * * * * * * *')   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 8765
    },
    "colab_type": "code",
    "id": "EOn1lzwngvUY",
    "outputId": "dcc35a37-c8ea-46d5-afee-5c7a162446a4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n",
      "model compiled\n",
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/100\n",
      "59980/59980 [==============================] - 159s 3ms/step - loss: 0.5457 - mean_absolute_error: 0.5523 - val_loss: 0.3872 - val_mean_absolute_error: 0.4659\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.38724, saving model to data/model_sc0\n",
      "Epoch 2/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.3434 - mean_absolute_error: 0.4422 - val_loss: 0.3025 - val_mean_absolute_error: 0.4051\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.38724 to 0.30247, saving model to data/model_sc0\n",
      "Epoch 3/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2926 - mean_absolute_error: 0.4094 - val_loss: 0.2606 - val_mean_absolute_error: 0.3812\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.30247 to 0.26064, saving model to data/model_sc0\n",
      "Epoch 4/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2666 - mean_absolute_error: 0.3914 - val_loss: 0.2501 - val_mean_absolute_error: 0.3782\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.26064 to 0.25006, saving model to data/model_sc0\n",
      "Epoch 5/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2507 - mean_absolute_error: 0.3799 - val_loss: 0.2759 - val_mean_absolute_error: 0.4031\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.25006\n",
      "Epoch 6/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2369 - mean_absolute_error: 0.3691 - val_loss: 0.2182 - val_mean_absolute_error: 0.3492\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.25006 to 0.21825, saving model to data/model_sc0\n",
      "Epoch 7/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2294 - mean_absolute_error: 0.3625 - val_loss: 0.2413 - val_mean_absolute_error: 0.3724\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.21825\n",
      "Epoch 8/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2221 - mean_absolute_error: 0.3566 - val_loss: 0.2193 - val_mean_absolute_error: 0.3458\n",
      "\n",
      "Epoch 00008: val_loss did not improve from 0.21825\n",
      "Epoch 9/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2173 - mean_absolute_error: 0.3516 - val_loss: 0.2052 - val_mean_absolute_error: 0.3403\n",
      "\n",
      "Epoch 00009: val_loss improved from 0.21825 to 0.20521, saving model to data/model_sc0\n",
      "Epoch 10/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.2100 - mean_absolute_error: 0.3458 - val_loss: 0.2039 - val_mean_absolute_error: 0.3392\n",
      "\n",
      "Epoch 00010: val_loss improved from 0.20521 to 0.20393, saving model to data/model_sc0\n",
      "Epoch 11/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2059 - mean_absolute_error: 0.3427 - val_loss: 0.1942 - val_mean_absolute_error: 0.3288\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.20393 to 0.19418, saving model to data/model_sc0\n",
      "Epoch 12/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.2018 - mean_absolute_error: 0.3386 - val_loss: 0.2028 - val_mean_absolute_error: 0.3373\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.19418\n",
      "Epoch 13/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1990 - mean_absolute_error: 0.3359 - val_loss: 0.2087 - val_mean_absolute_error: 0.3459\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.19418\n",
      "Epoch 14/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1952 - mean_absolute_error: 0.3323 - val_loss: 0.1913 - val_mean_absolute_error: 0.3291\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.19418 to 0.19132, saving model to data/model_sc0\n",
      "Epoch 15/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1953 - mean_absolute_error: 0.3328 - val_loss: 0.1913 - val_mean_absolute_error: 0.3266\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.19132\n",
      "Epoch 16/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1898 - mean_absolute_error: 0.3278 - val_loss: 0.1926 - val_mean_absolute_error: 0.3317\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.19132\n",
      "Epoch 17/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1872 - mean_absolute_error: 0.3253 - val_loss: 0.2030 - val_mean_absolute_error: 0.3424\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.19132\n",
      "Epoch 18/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1837 - mean_absolute_error: 0.3228 - val_loss: 0.1893 - val_mean_absolute_error: 0.3277\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.19132 to 0.18934, saving model to data/model_sc0\n",
      "Epoch 19/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1829 - mean_absolute_error: 0.3223 - val_loss: 0.1918 - val_mean_absolute_error: 0.3272\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.18934\n",
      "Epoch 20/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1803 - mean_absolute_error: 0.3195 - val_loss: 0.1794 - val_mean_absolute_error: 0.3162\n",
      "\n",
      "Epoch 00020: val_loss improved from 0.18934 to 0.17935, saving model to data/model_sc0\n",
      "Epoch 21/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1784 - mean_absolute_error: 0.3180 - val_loss: 0.1859 - val_mean_absolute_error: 0.3257\n",
      "\n",
      "Epoch 00021: val_loss did not improve from 0.17935\n",
      "Epoch 22/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1780 - mean_absolute_error: 0.3173 - val_loss: 0.2224 - val_mean_absolute_error: 0.3578\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.17935\n",
      "Epoch 23/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1732 - mean_absolute_error: 0.3137 - val_loss: 0.1869 - val_mean_absolute_error: 0.3250\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.17935\n",
      "Epoch 24/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1720 - mean_absolute_error: 0.3124 - val_loss: 0.1762 - val_mean_absolute_error: 0.3127\n",
      "\n",
      "Epoch 00024: val_loss improved from 0.17935 to 0.17621, saving model to data/model_sc0\n",
      "Epoch 25/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1686 - mean_absolute_error: 0.3083 - val_loss: 0.1870 - val_mean_absolute_error: 0.3259\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.17621\n",
      "Epoch 26/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1670 - mean_absolute_error: 0.3082 - val_loss: 0.1756 - val_mean_absolute_error: 0.3148\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.17621 to 0.17557, saving model to data/model_sc0\n",
      "Epoch 27/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1657 - mean_absolute_error: 0.3073 - val_loss: 0.1696 - val_mean_absolute_error: 0.3081\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.17557 to 0.16960, saving model to data/model_sc0\n",
      "Epoch 28/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1640 - mean_absolute_error: 0.3051 - val_loss: 0.1838 - val_mean_absolute_error: 0.3251\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.16960\n",
      "Epoch 29/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1634 - mean_absolute_error: 0.3043 - val_loss: 0.1790 - val_mean_absolute_error: 0.3184\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.16960\n",
      "Epoch 30/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1616 - mean_absolute_error: 0.3021 - val_loss: 0.1692 - val_mean_absolute_error: 0.3062\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.16960 to 0.16917, saving model to data/model_sc0\n",
      "Epoch 31/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1595 - mean_absolute_error: 0.3008 - val_loss: 0.1625 - val_mean_absolute_error: 0.2992\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.16917 to 0.16245, saving model to data/model_sc0\n",
      "Epoch 32/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1567 - mean_absolute_error: 0.2986 - val_loss: 0.2024 - val_mean_absolute_error: 0.3429\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.16245\n",
      "Epoch 33/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1580 - mean_absolute_error: 0.2998 - val_loss: 0.1607 - val_mean_absolute_error: 0.2968\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.16245 to 0.16071, saving model to data/model_sc0\n",
      "Epoch 34/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1554 - mean_absolute_error: 0.2965 - val_loss: 0.1855 - val_mean_absolute_error: 0.3254\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.16071\n",
      "Epoch 35/100\n",
      "59980/59980 [==============================] - 152s 3ms/step - loss: 0.1541 - mean_absolute_error: 0.2962 - val_loss: 0.1721 - val_mean_absolute_error: 0.3128\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.16071\n",
      "Epoch 36/100\n",
      "59980/59980 [==============================] - 152s 3ms/step - loss: 0.1520 - mean_absolute_error: 0.2940 - val_loss: 0.1937 - val_mean_absolute_error: 0.3376\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.16071\n",
      "Epoch 37/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1516 - mean_absolute_error: 0.2935 - val_loss: 0.1829 - val_mean_absolute_error: 0.3243\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.16071\n",
      "Epoch 38/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1492 - mean_absolute_error: 0.2919 - val_loss: 0.1879 - val_mean_absolute_error: 0.3303\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.16071\n",
      "* * * * * * * target 0 done * * * * * * *\n",
      "data loaded\n",
      "model compiled\n",
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/100\n",
      "59980/59980 [==============================] - 160s 3ms/step - loss: 0.2986 - mean_absolute_error: 0.4212 - val_loss: 0.1871 - val_mean_absolute_error: 0.3275\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.18710, saving model to data/model_sc1\n",
      "Epoch 2/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1801 - mean_absolute_error: 0.3228 - val_loss: 0.1459 - val_mean_absolute_error: 0.2825\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.18710 to 0.14585, saving model to data/model_sc1\n",
      "Epoch 3/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1497 - mean_absolute_error: 0.2912 - val_loss: 0.1386 - val_mean_absolute_error: 0.2719\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.14585 to 0.13863, saving model to data/model_sc1\n",
      "Epoch 4/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1397 - mean_absolute_error: 0.2798 - val_loss: 0.1263 - val_mean_absolute_error: 0.2565\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.13863 to 0.12635, saving model to data/model_sc1\n",
      "Epoch 5/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1310 - mean_absolute_error: 0.2700 - val_loss: 0.1246 - val_mean_absolute_error: 0.2515\n",
      "\n",
      "Epoch 00005: val_loss improved from 0.12635 to 0.12461, saving model to data/model_sc1\n",
      "Epoch 6/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.1267 - mean_absolute_error: 0.2654 - val_loss: 0.1122 - val_mean_absolute_error: 0.2415\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.12461 to 0.11222, saving model to data/model_sc1\n",
      "Epoch 7/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1228 - mean_absolute_error: 0.2607 - val_loss: 0.1133 - val_mean_absolute_error: 0.2420\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.11222\n",
      "Epoch 8/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1181 - mean_absolute_error: 0.2553 - val_loss: 0.1064 - val_mean_absolute_error: 0.2351\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.11222 to 0.10639, saving model to data/model_sc1\n",
      "Epoch 9/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1160 - mean_absolute_error: 0.2527 - val_loss: 0.1121 - val_mean_absolute_error: 0.2401\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.10639\n",
      "Epoch 10/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1113 - mean_absolute_error: 0.2476 - val_loss: 0.1144 - val_mean_absolute_error: 0.2411\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.10639\n",
      "Epoch 11/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1104 - mean_absolute_error: 0.2463 - val_loss: 0.0985 - val_mean_absolute_error: 0.2265\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.10639 to 0.09851, saving model to data/model_sc1\n",
      "Epoch 12/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1078 - mean_absolute_error: 0.2434 - val_loss: 0.1063 - val_mean_absolute_error: 0.2343\n",
      "\n",
      "Epoch 00012: val_loss did not improve from 0.09851\n",
      "Epoch 13/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1061 - mean_absolute_error: 0.2417 - val_loss: 0.1044 - val_mean_absolute_error: 0.2322\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.09851\n",
      "Epoch 14/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1021 - mean_absolute_error: 0.2368 - val_loss: 0.0918 - val_mean_absolute_error: 0.2191\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.09851 to 0.09179, saving model to data/model_sc1\n",
      "Epoch 15/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1005 - mean_absolute_error: 0.2358 - val_loss: 0.1245 - val_mean_absolute_error: 0.2519\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.09179\n",
      "Epoch 16/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0983 - mean_absolute_error: 0.2330 - val_loss: 0.0976 - val_mean_absolute_error: 0.2248\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.09179\n",
      "Epoch 17/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0961 - mean_absolute_error: 0.2301 - val_loss: 0.0940 - val_mean_absolute_error: 0.2219\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.09179\n",
      "Epoch 18/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0955 - mean_absolute_error: 0.2297 - val_loss: 0.0912 - val_mean_absolute_error: 0.2168\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.09179 to 0.09116, saving model to data/model_sc1\n",
      "Epoch 19/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0931 - mean_absolute_error: 0.2264 - val_loss: 0.0883 - val_mean_absolute_error: 0.2126\n",
      "\n",
      "Epoch 00019: val_loss improved from 0.09116 to 0.08835, saving model to data/model_sc1\n",
      "Epoch 20/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0917 - mean_absolute_error: 0.2241 - val_loss: 0.0917 - val_mean_absolute_error: 0.2152\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.08835\n",
      "Epoch 21/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0905 - mean_absolute_error: 0.2228 - val_loss: 0.0853 - val_mean_absolute_error: 0.2093\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.08835 to 0.08528, saving model to data/model_sc1\n",
      "Epoch 22/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0892 - mean_absolute_error: 0.2213 - val_loss: 0.0822 - val_mean_absolute_error: 0.2060\n",
      "\n",
      "Epoch 00022: val_loss improved from 0.08528 to 0.08221, saving model to data/model_sc1\n",
      "Epoch 23/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0866 - mean_absolute_error: 0.2183 - val_loss: 0.0828 - val_mean_absolute_error: 0.2063\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.08221\n",
      "Epoch 24/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0875 - mean_absolute_error: 0.2193 - val_loss: 0.0833 - val_mean_absolute_error: 0.2067\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.08221\n",
      "Epoch 25/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0858 - mean_absolute_error: 0.2161 - val_loss: 0.0852 - val_mean_absolute_error: 0.2104\n",
      "\n",
      "Epoch 00025: val_loss did not improve from 0.08221\n",
      "Epoch 26/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0865 - mean_absolute_error: 0.2180 - val_loss: 0.0820 - val_mean_absolute_error: 0.2056\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.08221 to 0.08203, saving model to data/model_sc1\n",
      "Epoch 27/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0840 - mean_absolute_error: 0.2148 - val_loss: 0.0864 - val_mean_absolute_error: 0.2108\n",
      "\n",
      "Epoch 00027: val_loss did not improve from 0.08203\n",
      "Epoch 28/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0833 - mean_absolute_error: 0.2136 - val_loss: 0.0792 - val_mean_absolute_error: 0.2011\n",
      "\n",
      "Epoch 00028: val_loss improved from 0.08203 to 0.07918, saving model to data/model_sc1\n",
      "Epoch 29/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0812 - mean_absolute_error: 0.2114 - val_loss: 0.0806 - val_mean_absolute_error: 0.2023\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.07918\n",
      "Epoch 30/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0811 - mean_absolute_error: 0.2115 - val_loss: 0.0785 - val_mean_absolute_error: 0.2015\n",
      "\n",
      "Epoch 00030: val_loss improved from 0.07918 to 0.07851, saving model to data/model_sc1\n",
      "Epoch 31/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0811 - mean_absolute_error: 0.2107 - val_loss: 0.0836 - val_mean_absolute_error: 0.2059\n",
      "\n",
      "Epoch 00031: val_loss did not improve from 0.07851\n",
      "Epoch 32/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0801 - mean_absolute_error: 0.2101 - val_loss: 0.0768 - val_mean_absolute_error: 0.1957\n",
      "\n",
      "Epoch 00032: val_loss improved from 0.07851 to 0.07676, saving model to data/model_sc1\n",
      "Epoch 33/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0794 - mean_absolute_error: 0.2090 - val_loss: 0.0760 - val_mean_absolute_error: 0.1969\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.07676 to 0.07596, saving model to data/model_sc1\n",
      "Epoch 34/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0777 - mean_absolute_error: 0.2074 - val_loss: 0.0752 - val_mean_absolute_error: 0.1973\n",
      "\n",
      "Epoch 00034: val_loss improved from 0.07596 to 0.07523, saving model to data/model_sc1\n",
      "Epoch 35/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0770 - mean_absolute_error: 0.2060 - val_loss: 0.0767 - val_mean_absolute_error: 0.1975\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.07523\n",
      "Epoch 36/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0764 - mean_absolute_error: 0.2052 - val_loss: 0.0734 - val_mean_absolute_error: 0.1923\n",
      "\n",
      "Epoch 00036: val_loss improved from 0.07523 to 0.07343, saving model to data/model_sc1\n",
      "Epoch 37/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0760 - mean_absolute_error: 0.2049 - val_loss: 0.0805 - val_mean_absolute_error: 0.2008\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.07343\n",
      "Epoch 38/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0747 - mean_absolute_error: 0.2034 - val_loss: 0.0788 - val_mean_absolute_error: 0.2004\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.07343\n",
      "Epoch 39/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0748 - mean_absolute_error: 0.2034 - val_loss: 0.0739 - val_mean_absolute_error: 0.1913\n",
      "\n",
      "Epoch 00039: val_loss did not improve from 0.07343\n",
      "Epoch 40/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0752 - mean_absolute_error: 0.2035 - val_loss: 0.0752 - val_mean_absolute_error: 0.1933\n",
      "\n",
      "Epoch 00040: val_loss did not improve from 0.07343\n",
      "Epoch 41/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0743 - mean_absolute_error: 0.2027 - val_loss: 0.0745 - val_mean_absolute_error: 0.1927\n",
      "\n",
      "Epoch 00041: val_loss did not improve from 0.07343\n",
      "* * * * * * * target 1 done * * * * * * *\n",
      "data loaded\n",
      "model compiled\n",
      "Train on 59980 samples, validate on 14995 samples\n",
      "Epoch 1/100\n",
      "59980/59980 [==============================] - 161s 3ms/step - loss: 0.3678 - mean_absolute_error: 0.4322 - val_loss: 0.2739 - val_mean_absolute_error: 0.4377\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.27389, saving model to data/model_sc3\n",
      "Epoch 2/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1506 - mean_absolute_error: 0.2893 - val_loss: 0.0934 - val_mean_absolute_error: 0.2272\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.27389 to 0.09341, saving model to data/model_sc3\n",
      "Epoch 3/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.1204 - mean_absolute_error: 0.2543 - val_loss: 0.0630 - val_mean_absolute_error: 0.1807\n",
      "\n",
      "Epoch 00003: val_loss improved from 0.09341 to 0.06296, saving model to data/model_sc3\n",
      "Epoch 4/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0961 - mean_absolute_error: 0.2255 - val_loss: 0.0752 - val_mean_absolute_error: 0.1962\n",
      "\n",
      "Epoch 00004: val_loss did not improve from 0.06296\n",
      "Epoch 5/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0884 - mean_absolute_error: 0.2116 - val_loss: 0.0765 - val_mean_absolute_error: 0.1762\n",
      "\n",
      "Epoch 00005: val_loss did not improve from 0.06296\n",
      "Epoch 6/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0780 - mean_absolute_error: 0.1971 - val_loss: 0.0357 - val_mean_absolute_error: 0.1326\n",
      "\n",
      "Epoch 00006: val_loss improved from 0.06296 to 0.03568, saving model to data/model_sc3\n",
      "Epoch 7/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0686 - mean_absolute_error: 0.1835 - val_loss: 0.0497 - val_mean_absolute_error: 0.1543\n",
      "\n",
      "Epoch 00007: val_loss did not improve from 0.03568\n",
      "Epoch 8/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0686 - mean_absolute_error: 0.1818 - val_loss: 0.0312 - val_mean_absolute_error: 0.1222\n",
      "\n",
      "Epoch 00008: val_loss improved from 0.03568 to 0.03121, saving model to data/model_sc3\n",
      "Epoch 9/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0610 - mean_absolute_error: 0.1716 - val_loss: 0.0403 - val_mean_absolute_error: 0.1230\n",
      "\n",
      "Epoch 00009: val_loss did not improve from 0.03121\n",
      "Epoch 10/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0572 - mean_absolute_error: 0.1661 - val_loss: 0.0313 - val_mean_absolute_error: 0.1209\n",
      "\n",
      "Epoch 00010: val_loss did not improve from 0.03121\n",
      "Epoch 11/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0557 - mean_absolute_error: 0.1634 - val_loss: 0.0306 - val_mean_absolute_error: 0.1277\n",
      "\n",
      "Epoch 00011: val_loss improved from 0.03121 to 0.03064, saving model to data/model_sc3\n",
      "Epoch 12/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0541 - mean_absolute_error: 0.1611 - val_loss: 0.0221 - val_mean_absolute_error: 0.1017\n",
      "\n",
      "Epoch 00012: val_loss improved from 0.03064 to 0.02214, saving model to data/model_sc3\n",
      "Epoch 13/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0540 - mean_absolute_error: 0.1591 - val_loss: 0.0394 - val_mean_absolute_error: 0.1351\n",
      "\n",
      "Epoch 00013: val_loss did not improve from 0.02214\n",
      "Epoch 14/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0502 - mean_absolute_error: 0.1543 - val_loss: 0.0200 - val_mean_absolute_error: 0.0979\n",
      "\n",
      "Epoch 00014: val_loss improved from 0.02214 to 0.01996, saving model to data/model_sc3\n",
      "Epoch 15/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0522 - mean_absolute_error: 0.1555 - val_loss: 0.0228 - val_mean_absolute_error: 0.1062\n",
      "\n",
      "Epoch 00015: val_loss did not improve from 0.01996\n",
      "Epoch 16/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0471 - mean_absolute_error: 0.1487 - val_loss: 0.0352 - val_mean_absolute_error: 0.1121\n",
      "\n",
      "Epoch 00016: val_loss did not improve from 0.01996\n",
      "Epoch 17/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0476 - mean_absolute_error: 0.1497 - val_loss: 0.0224 - val_mean_absolute_error: 0.0964\n",
      "\n",
      "Epoch 00017: val_loss did not improve from 0.01996\n",
      "Epoch 18/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0472 - mean_absolute_error: 0.1475 - val_loss: 0.0177 - val_mean_absolute_error: 0.0932\n",
      "\n",
      "Epoch 00018: val_loss improved from 0.01996 to 0.01769, saving model to data/model_sc3\n",
      "Epoch 19/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0430 - mean_absolute_error: 0.1416 - val_loss: 0.0185 - val_mean_absolute_error: 0.0913\n",
      "\n",
      "Epoch 00019: val_loss did not improve from 0.01769\n",
      "Epoch 20/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0435 - mean_absolute_error: 0.1412 - val_loss: 0.0205 - val_mean_absolute_error: 0.0987\n",
      "\n",
      "Epoch 00020: val_loss did not improve from 0.01769\n",
      "Epoch 21/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0398 - mean_absolute_error: 0.1359 - val_loss: 0.0147 - val_mean_absolute_error: 0.0841\n",
      "\n",
      "Epoch 00021: val_loss improved from 0.01769 to 0.01466, saving model to data/model_sc3\n",
      "Epoch 22/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0406 - mean_absolute_error: 0.1367 - val_loss: 0.0162 - val_mean_absolute_error: 0.0840\n",
      "\n",
      "Epoch 00022: val_loss did not improve from 0.01466\n",
      "Epoch 23/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0401 - mean_absolute_error: 0.1342 - val_loss: 0.0158 - val_mean_absolute_error: 0.0881\n",
      "\n",
      "Epoch 00023: val_loss did not improve from 0.01466\n",
      "Epoch 24/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0378 - mean_absolute_error: 0.1311 - val_loss: 0.0156 - val_mean_absolute_error: 0.0792\n",
      "\n",
      "Epoch 00024: val_loss did not improve from 0.01466\n",
      "Epoch 25/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0385 - mean_absolute_error: 0.1314 - val_loss: 0.0127 - val_mean_absolute_error: 0.0745\n",
      "\n",
      "Epoch 00025: val_loss improved from 0.01466 to 0.01265, saving model to data/model_sc3\n",
      "Epoch 26/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0332 - mean_absolute_error: 0.1232 - val_loss: 0.0121 - val_mean_absolute_error: 0.0701\n",
      "\n",
      "Epoch 00026: val_loss improved from 0.01265 to 0.01212, saving model to data/model_sc3\n",
      "Epoch 27/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0328 - mean_absolute_error: 0.1219 - val_loss: 0.0098 - val_mean_absolute_error: 0.0663\n",
      "\n",
      "Epoch 00027: val_loss improved from 0.01212 to 0.00976, saving model to data/model_sc3\n",
      "Epoch 28/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0322 - mean_absolute_error: 0.1204 - val_loss: 0.0109 - val_mean_absolute_error: 0.0691\n",
      "\n",
      "Epoch 00028: val_loss did not improve from 0.00976\n",
      "Epoch 29/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0313 - mean_absolute_error: 0.1181 - val_loss: 0.0154 - val_mean_absolute_error: 0.0735\n",
      "\n",
      "Epoch 00029: val_loss did not improve from 0.00976\n",
      "Epoch 30/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0314 - mean_absolute_error: 0.1183 - val_loss: 0.0256 - val_mean_absolute_error: 0.0978\n",
      "\n",
      "Epoch 00030: val_loss did not improve from 0.00976\n",
      "Epoch 31/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1167 - val_loss: 0.0095 - val_mean_absolute_error: 0.0621\n",
      "\n",
      "Epoch 00031: val_loss improved from 0.00976 to 0.00953, saving model to data/model_sc3\n",
      "Epoch 32/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0292 - mean_absolute_error: 0.1138 - val_loss: 0.0112 - val_mean_absolute_error: 0.0693\n",
      "\n",
      "Epoch 00032: val_loss did not improve from 0.00953\n",
      "Epoch 33/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.0312 - mean_absolute_error: 0.1159 - val_loss: 0.0083 - val_mean_absolute_error: 0.0584\n",
      "\n",
      "Epoch 00033: val_loss improved from 0.00953 to 0.00829, saving model to data/model_sc3\n",
      "Epoch 34/100\n",
      "59980/59980 [==============================] - 153s 3ms/step - loss: 0.0272 - mean_absolute_error: 0.1099 - val_loss: 0.0112 - val_mean_absolute_error: 0.0696\n",
      "\n",
      "Epoch 00034: val_loss did not improve from 0.00829\n",
      "Epoch 35/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0276 - mean_absolute_error: 0.1101 - val_loss: 0.0086 - val_mean_absolute_error: 0.0598\n",
      "\n",
      "Epoch 00035: val_loss did not improve from 0.00829\n",
      "Epoch 36/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0266 - mean_absolute_error: 0.1088 - val_loss: 0.0126 - val_mean_absolute_error: 0.0642\n",
      "\n",
      "Epoch 00036: val_loss did not improve from 0.00829\n",
      "Epoch 37/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0269 - mean_absolute_error: 0.1076 - val_loss: 0.0086 - val_mean_absolute_error: 0.0603\n",
      "\n",
      "Epoch 00037: val_loss did not improve from 0.00829\n",
      "Epoch 38/100\n",
      "59980/59980 [==============================] - 154s 3ms/step - loss: 0.0258 - mean_absolute_error: 0.1066 - val_loss: 0.0115 - val_mean_absolute_error: 0.0638\n",
      "\n",
      "Epoch 00038: val_loss did not improve from 0.00829\n",
      "* * * * * * * target 3 done * * * * * * *\n"
     ]
    }
   ],
   "source": [
    "for tgt in [0,1,3]:\n",
    "  with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:\n",
    "      target = file.read().splitlines()\n",
    "\n",
    "  target_train = np.array([target[elt] for elt in idxs_select_train]).astype('float')\n",
    "  target_val = np.array([target[elt] for elt in idxs_select_val]).astype('float')\n",
    "\n",
    "  print('data loaded')\n",
    "\n",
    "  # = = = = = defining architecture = = = = =\n",
    "\n",
    "  sent_ints = Input(shape=(docs_train.shape[2],))\n",
    "\n",
    "  sent_wv = Embedding(input_dim=embeddings.shape[0],\n",
    "                      output_dim=embeddings.shape[1],\n",
    "                      weights=[embeddings],\n",
    "                      input_length=docs_train.shape[2],\n",
    "                      trainable=False,\n",
    "                      )(sent_ints)\n",
    "\n",
    "  ## HAN sent encoder\n",
    "  sent_wv_dr = Dropout(drop_rate)(sent_wv)\n",
    "  # sent_wv_dr = BatchNormalization(sent_wv_dr) ######\n",
    "  sent_wa = bidir_gru(sent_wv_dr, n_units, is_GPU)\n",
    "  sent_wa = bidir_gru(sent_wa, n_units, is_GPU) #########\n",
    "  sent_att_vec, word_att_coeffs = AttentionWithContext(return_coefficients=True)(sent_wa)\n",
    "  sent_att_vec_dr = Dropout(drop_rate)(sent_att_vec)\n",
    "  # sent_att_vec_dr = BatchNormalization(sent_att_vec_dr) ######\n",
    "  # skip connection\n",
    "  sent_added = SkipConnection()([sent_att_vec_dr, sent_wv_dr])\n",
    "  sent_encoder = Model(sent_ints, sent_added)\n",
    "\n",
    "  ## structured self-attentive\n",
    "  mc_sent_wv_dr = Dropout(drop_rate)(sent_wv)\n",
    "  # mc_sent_wv_dr = BatchNormalization(mc_sent_wv_dr) ######\n",
    "  mc_sent_wa = bidir_lstm(mc_sent_wv_dr, mc_n_units, is_GPU)\n",
    "  mc_sent_wa = bidir_lstm(mc_sent_wa, mc_n_units, is_GPU) #######\n",
    "  mc_sent_att_vec, mc_word_att_coeffs = StructuredSelfAttentive(da=da, r=r, return_coefficients=True)(mc_sent_wa)\n",
    "  mc_sent_att_vec_dr = Dropout(drop_rate)(mc_sent_att_vec)\n",
    "  # mc_sent_att_vec_dr = BatchNormalization(mc_sent_att_vec_dr) ######\n",
    "  # skip connection\n",
    "  mc_sent_added = SkipConnection()([mc_sent_att_vec_dr, mc_sent_wv_dr])\n",
    "  mc_sent_encoder = Model(sent_ints, mc_sent_added)\n",
    "\n",
    "  ## combine context and target\n",
    "  doc_ints = Input(shape=(docs_train.shape[1], docs_train.shape[2],))\n",
    "  # sentence encoder\n",
    "  sent_att_vecs_dr = TimeDistributed(sent_encoder)(doc_ints)\n",
    "  doc_sa = bidir_gru(sent_att_vecs_dr, n_units, is_GPU)\n",
    "  # context\n",
    "  mc_sent_att_vecs_dr = TimeDistributed(mc_sent_encoder)(doc_ints)\n",
    "  mc_doc_sa = bidir_gru(mc_sent_att_vecs_dr, n_units, is_GPU)\n",
    "\n",
    "  doc_att_vec, sent_att_coeffs = AttentionWithMultiContext(return_coefficients=True)([doc_sa, mc_doc_sa])\n",
    "  doc_att_vec_dr = Dropout(drop_rate)(doc_att_vec)\n",
    "  # doc_att_vec_dr = BatchNormalization(doc_att_vec_dr) ######\n",
    "\n",
    "  # new\n",
    "  # hid = Dense(units=4, activation='tanh')(doc_att_vec_dr)\n",
    "  # hid1 = Dense(units=16, activation='relu')(doc_att_vec_dr) ###\n",
    "  # hid1r = Dropout(drop_rate)(hid1)\n",
    "  # hid2 = Dense(units=16, activation='relu')(hid1r)\n",
    "  # hid2r = Dropout(drop_rate)(hid2)\n",
    "  # hid3 = Dense(units=16, activation='relu')(hid2r)\n",
    "  # hid3r = Dropout(drop_rate)(hid3)\n",
    "  # hid4 = Dense(units=16, activation='relu')(hid3r)\n",
    "  # hid4r = Dropout(drop_rate)(hid4)\n",
    "  #   hid1 = Dense(units=32, activation='sigmoid')(doc_att_vec_dr)\n",
    "  #   hid2 = Dense(units=8, activation='sigmoid')(hid1)\n",
    "  hid1 = LeakyReLU(alpha=0.01)(doc_att_vec_dr)\n",
    "  hid2 = LeakyReLU(alpha=0.01)(hid1)\n",
    "  preds = Dense(units=1)(hid2)\n",
    "\n",
    "  model = Model(doc_ints, preds)\n",
    "\n",
    "  model.compile(loss='mean_squared_error', optimizer=my_optimizer, metrics=['mae'])\n",
    "\n",
    "  print('model compiled')\n",
    "\n",
    "  # = = = = = training = = = = =\n",
    "\n",
    "  early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                  patience=my_patience,\n",
    "                                  mode='min')\n",
    "\n",
    "  # save model corresponding to best epoch\n",
    "  checkpointer = ModelCheckpoint(filepath=path_to_data + 'model_sc' + str(tgt), \n",
    "                                  verbose=1, \n",
    "                                  save_best_only=True,\n",
    "                                  save_weights_only=True)\n",
    "\n",
    "  if save_weights:\n",
    "      my_callbacks = [early_stopping, checkpointer]\n",
    "  else:\n",
    "      my_callbacks = [early_stopping]\n",
    "\n",
    "  model.fit(docs_train, \n",
    "              target_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = nb_epochs,\n",
    "              validation_data = (docs_val,target_val),\n",
    "              callbacks = my_callbacks)\n",
    "\n",
    "  hist = model.history.history\n",
    "\n",
    "  if save_history:\n",
    "      with open(path_to_data + 'model_history_sc' + str(tgt) + '_sc.json', 'w') as file:\n",
    "          json.dump(hist, file, sort_keys=False, indent=4)\n",
    "\n",
    "  print('* * * * * * * target',tgt,'done * * * * * * *')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hJAs4d8bcGiA"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kaggle_main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
