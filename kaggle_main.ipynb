{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "4H4EJY3OQNmB"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import json\n",
    "import utils\n",
    "import numpy as np\n",
    "\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, Embedding, Dropout, Bidirectional, GRU, CuDNNGRU, TimeDistributed, Dense\n",
    "\n",
    "from time import time\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "start_time = time()\n",
    "\n",
    "is_GPU = True\n",
    "save_weights = True\n",
    "save_history = True\n",
    "\n",
    "path_root = '' # fill me!\n",
    "path_to_code = path_root\n",
    "path_to_data = path_root + 'data/'\n",
    "\n",
    "sys.path.insert(0, path_to_code)\n",
    "\n",
    "# = = = = = = = = = = = = = = =\n",
    "\n",
    "from AttentionWithContext import AttentionWithContext\n",
    "\n",
    "def bidir_gru(my_seq,n_units,is_GPU):\n",
    "    '''\n",
    "    just a convenient wrapper for bidirectional RNN with GRU units\n",
    "    enables CUDA acceleration on GPU\n",
    "    # regardless of whether training is done on GPU, model can be loaded on CPU\n",
    "    # see: https://github.com/keras-team/keras/pull/9112\n",
    "    '''\n",
    "    if is_GPU:\n",
    "        return Bidirectional(CuDNNGRU(units=n_units,\n",
    "                                      return_sequences=True),\n",
    "                             merge_mode='concat', weights=None)(my_seq)\n",
    "    else:\n",
    "        return Bidirectional(GRU(units=n_units,\n",
    "                                 activation='tanh', \n",
    "                                 dropout=0.0,\n",
    "                                 recurrent_dropout=0.0,\n",
    "                                 implementation=1,\n",
    "                                 return_sequences=True,\n",
    "                                 reset_after=True,\n",
    "                                 recurrent_activation='sigmoid'),\n",
    "                             merge_mode='concat', weights=None)(my_seq)\n",
    "\n",
    "\n",
    "# = = = = = hyper-parameters = = = = =\n",
    "\n",
    "n_units = 50\n",
    "drop_rate = 0.5\n",
    "batch_size = 96\n",
    "nb_epochs = 10\n",
    "my_optimizer = 'adam'\n",
    "my_patience = 4\n",
    "embed_max = 1\n",
    "embed_min = -1\n",
    "node_max = 1\n",
    "node_min = -1\n",
    "\n",
    "# = = = = = data loading = = = = =\n",
    "\n",
    "docs = np.load(path_to_data + 'documents_p1q1.npy')\n",
    "embeddings = utils.embed_weight(path_to_data, 'embeddings.npy', 'node_embed_p1q1.npy',\n",
    "                                embed_max, embed_min, node_max, node_min)\n",
    "\n",
    "with open(path_to_data + 'train_idxs.txt', 'r') as file:\n",
    "    train_idxs = file.read().splitlines()\n",
    "    \n",
    "train_idxs = [int(elt) for elt in train_idxs]\n",
    "    \n",
    "# create validation set\n",
    "np.random.seed(12219)\n",
    "idxs_select_train = np.random.choice(range(len(train_idxs)),size=int(len(train_idxs)*0.80),replace=False)\n",
    "idxs_select_val = np.setdiff1d(range(len(train_idxs)),idxs_select_train)\n",
    "\n",
    "train_idxs_new = [train_idxs[elt] for elt in idxs_select_train]\n",
    "val_idxs = [train_idxs[elt] for elt in idxs_select_val]\n",
    "\n",
    "docs_train = docs[train_idxs_new,:,:]\n",
    "docs_val = docs[val_idxs,:,:]\n",
    "\n",
    "for tgt in range(2):\n",
    "\n",
    "    with open(path_to_data + 'targets/train/target_' + str(tgt) + '.txt', 'r') as file:\n",
    "        target = file.read().splitlines()\n",
    "    \n",
    "    target_train = np.array([target[elt] for elt in idxs_select_train]).astype('float')\n",
    "    target_val = np.array([target[elt] for elt in idxs_select_val]).astype('float')\n",
    "\n",
    "    print('data loaded')\n",
    "\n",
    "    # = = = = = defining architecture = = = = =\n",
    "\n",
    "    sent_ints = Input(shape=(docs_train.shape[2],))\n",
    "\n",
    "    sent_wv = Embedding(input_dim=embeddings.shape[0],\n",
    "                        output_dim=embeddings.shape[1],\n",
    "                        weights=[embeddings],\n",
    "                        input_length=docs_train.shape[2],\n",
    "                        trainable=False,\n",
    "                        )(sent_ints)\n",
    "\n",
    "    sent_wv_dr = Dropout(drop_rate)(sent_wv)\n",
    "    sent_wa = bidir_gru(sent_wv_dr,n_units,is_GPU)\n",
    "    sent_att_vec,word_att_coeffs = AttentionWithContext(return_coefficients=True)(sent_wa)\n",
    "    sent_att_vec_dr = Dropout(drop_rate)(sent_att_vec)                      \n",
    "    sent_encoder = Model(sent_ints,sent_att_vec_dr)\n",
    "\n",
    "    doc_ints = Input(shape=(docs_train.shape[1],docs_train.shape[2],))\n",
    "    sent_att_vecs_dr = TimeDistributed(sent_encoder)(doc_ints)\n",
    "    doc_sa = bidir_gru(sent_att_vecs_dr,n_units,is_GPU)\n",
    "    doc_att_vec,sent_att_coeffs = AttentionWithContext(return_coefficients=True)(doc_sa)\n",
    "    doc_att_vec_dr = Dropout(drop_rate)(doc_att_vec)\n",
    "\n",
    "    preds = Dense(units=1,\n",
    "                  activation='sigmoid')(doc_att_vec_dr)\n",
    "    model = Model(doc_ints,preds)\n",
    "\n",
    "    model.compile(loss='mean_squared_error',\n",
    "                  optimizer=my_optimizer,\n",
    "                  metrics=['mae'])\n",
    "\n",
    "    print('model compiled')\n",
    "\n",
    "    # = = = = = training = = = = =\n",
    "\n",
    "    early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                   patience=my_patience,\n",
    "                                   mode='min')\n",
    "\n",
    "    # save model corresponding to best epoch\n",
    "    checkpointer = ModelCheckpoint(filepath=path_to_data + 'model_' + str(tgt), \n",
    "                                   verbose=1, \n",
    "                                   save_best_only=True,\n",
    "                                   save_weights_only=True)\n",
    "\n",
    "    if save_weights:\n",
    "        my_callbacks = [early_stopping,checkpointer]\n",
    "    else:\n",
    "        my_callbacks = [early_stopping]\n",
    "\n",
    "    model.fit(docs_train, \n",
    "              target_train,\n",
    "              batch_size = batch_size,\n",
    "              epochs = nb_epochs,\n",
    "              validation_data = (docs_val,target_val),\n",
    "              callbacks = my_callbacks)\n",
    "\n",
    "    hist = model.history.history\n",
    "\n",
    "    if save_history:\n",
    "        with open(path_to_data + 'model_history_' + str(tgt) + '.json', 'w') as file:\n",
    "            json.dump(hist, file, sort_keys=False, indent=4)\n",
    "\n",
    "    print('* * * * * * * target',tgt,'done * * * * * * *')    \n",
    "    \n",
    "print('everything done in', round(time() - start_time,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QfFdqAdXYl1n"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "kaggle_main.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
